Fancy stuff
============================
author: David L Miller
css: custom.css

A word of warning
=================

<br/>
<br/>
<br/>
![jenny is the best](images/jenny_models.png)


Away from the exponential family
===================================
type:section


```{r setup, include=F}
library(mgcv)
library(ggplot2)
```

```{r pres_setup, include =F}
library(knitr)
opts_chunk$set(cache=TRUE, echo=FALSE,fig.align="center")
```


Modelling "counts"
================
type:section

Counts and count-like things
============================

- Response is a count (not always integer)
- Often, it's mostly zero (that's complicated)
- Could also be catch per unit effort, biomass etc
- Flexible mean-variance relationship

![The Count from Sesame Street](images/count.jpg)

Tweedie distribution
=====================

```{r tweedie}
library(tweedie)
library(RColorBrewer)

# tweedie
y<-seq(0.01,5,by=0.01)
pows <- seq(1.2, 1.9, by=0.1)

fymat <- matrix(NA, length(y), length(pows))

i <- 1
for(pow in pows){
  fymat[,i] <- dtweedie( y=y, power=pow, mu=2, phi=1)
  i <- i+1
}

plot(range(y), range(fymat), type="n", ylab="Density", xlab="x", cex.lab=1.5,
     main="")

rr <- brewer.pal(8,"Dark2")

for(i in 1:ncol(fymat)){
  lines(y, fymat[,i], type="l", col=rr[i], lwd=2)
}
```
***
-  $\text{Var}\left(\text{count}\right) = \phi\mathbb{E}(\text{count})^q$
- Common distributions are sub-cases:
  - $q=1 \Rightarrow$ Poisson
  - $q=2 \Rightarrow$ Gamma
  - $q=3 \Rightarrow$ Normal
- We are interested in $1 < q < 2$ 
- (here $q = 1.2, 1.3, \ldots, 1.9$)
- `tw()`


Negative binomial
==================

```{r negbin}
y<-seq(1,12,by=1)
disps <- seq(0.001, 1, len=10)

fymat <- matrix(NA, length(y), length(disps))

i <- 1
for(disp in disps){
  fymat[,i] <- dnbinom(y, size=disp, mu=5)
  i <- i+1
}

plot(range(y), range(fymat), type="n", ylab="Density", xlab="x", cex.lab=1.5,
     main="")

rr <- brewer.pal(8,"Dark2")

for(i in 1:ncol(fymat)){
  lines(y, fymat[,i], type="l", col=rr[i], lwd=2)
}
```
***
- $\text{Var}\left(\text{count}\right) =$ $\mathbb{E}(\text{count}) + \kappa \mathbb{E}(\text{count})^2$
- Estimate $\kappa$
- Is quadratic relationship a "strong" assumption?
- Similar to Poisson: $\text{Var}\left(\text{count}\right) =\mathbb{E}(\text{count})$ 
- `nb()`


Zero-inflated distributions
===========================

- Models the probability of zeros seperately from mean counts given that you've observed more than zero
at a location.
- `ziP` and `ziplss` (for location-scale models)
- zero inflation is assessed *conditional* on the model
  - is what you have zero inflation or just lots of zeros?
  - don't just jump straight to zero inflation



Other distributions
======================
type:section 

The Beta distribution
======================

```{r beta-dist}
shape1 <- c(0.2, 1, 5, 1, 3, 1.5)
shape2 <- c(0.2, 3, 1, 1, 1.5, 3)
x <- seq(0.01, 0.99, length = 200)
rr <- brewer.pal(length(shape1), "Dark2")
fymat <- mapply(dbeta, shape1, shape2, MoreArgs = list(x = x))
matplot(x, fymat, type = "l", col = rr, lwd = 2, lty = "solid")
legend("top", bty = "n",
       legend = expression(alpha == 0.2 ~~ beta == 0.2,
                           alpha == 1.0 ~~ beta == 3.0,
                           alpha == 5.0 ~~ beta == 1.0,
                           alpha == 1.0 ~~ beta == 1.0,
                           alpha == 3.0 ~~ beta == 1.5,
                           alpha == 1.5 ~~ beta == 3.0),
       col = rr, cex = 1.25, lty = "solid", lwd = 2)
```

***

- Proportions; continuous, bounded at 0 & 1
- Beta distribution is convenient choice
- Two strictly positive shape parameters, $\alpha$ & $\beta$
- Has support on $x \in (0,1)$
- Density at $x = 0$ & $x = 1$ is $\infty$, fudge
- `betar()` family in **mgcv**

t-distribution
============================
- Models continuous data w/ longer tails than normal
- Far less sensitive to outliers
- Has one extra parameter: df. 
- bigger df: t dist approaches normal


```{r texample2, include =T,echo=F,results= "hide", fig.width=15, fig.height=8}
set.seed(4)
n=300
dat = data.frame(x=seq(0,10,length=n))
dat$f = 20*exp(-dat$x)*dat$x
dat$y  = 1*rt(n,df = 3) + dat$f
norm_mod =  gam(y~s(x,k=20), data=dat, family=gaussian(link="identity"))
t_mod = gam(y~s(x,k=20), data=dat, family=scat(link="identity"))
predict_norm = predict(norm_mod,se.fit=T)
predict_t = predict(t_mod,se.fit=T)
fit_vals = data.frame(x = c(dat$x,dat$x), 
                      fit =c(predict_norm[[1]],predict_t[[1]]),
                      se_min = c(predict_norm[[1]] - 2*predict_norm[[2]],
                                 predict_t[[1]] - 2*predict_t[[2]]),
                      se_max = c(predict_norm[[1]] + 2*predict_norm[[2]],
                                 predict_t[[1]] + 2*predict_t[[2]]),
                      model = rep(c("normal errors","t-errors"),each=n))
ggplot(aes(x=x,y=fit),data=fit_vals)+
  facet_grid(.~model)+
  geom_line(col="red")+
  geom_ribbon(aes(ymin =se_min,ymax = se_max),alpha=0.5,fill="red")+
  annotate(x = dat$x,y=dat$y,size=2,geom="point")+
  annotate(x = dat$x,y=dat$f,size=2,geom="line")+
  theme_bw(20)
```



Ordered categorical data 
===========================
```{r ocat_ex2, include =T,echo=F,results= "hide", fig.width=6}
set.seed(4)
n= 100
dat  = data.frame(body_size = seq(-2,2, length=200))
dat$linear_predictor = 6*exp(dat$body_size*2)/(1+exp(dat$body_size*2))-2

ggplot(aes(x=body_size, y=linear_predictor),data=dat) + 
  geom_line()+
  geom_ribbon(aes(ymin=linear_predictor-1,ymax=linear_predictor+1),alpha=0.25)+
  annotate(x= dat$body_size, ymin=-3,ymax=-1, alpha=0.25,geom="ribbon")+
  annotate(x= 0, y=-2, label = "least concern",geom="text",size=10)+
  annotate(x= dat$body_size, ymin=-1,ymax=1.5, alpha=0.25,geom="ribbon",fill="red")+
  annotate(x= 0, y=0.25, label = "vulnerable",geom="text",size=10)+
  annotate(x= dat$body_size, ymin=1.5,ymax=2, alpha=0.25,geom="ribbon",fill="blue")+
  annotate(x= 0, y=1.75, label = "endangered",geom="text",size=10)+
  annotate(x= 0, y=3.5, label = "extinct",geom="text",size=10)+
  scale_x_continuous("relative body size", expand=c(0,0))+
  scale_y_continuous("linear predictor",limits=c(-3,5), expand=c(0,0))+
  theme_bw(30)+
  theme(panel.grid = element_blank())

```

***

- Data are categories, have order
- e.g.: conservation status: "least concern", "vulnerable", "endangered", "extinct"
- fits a linear latent model using covariates, w/ threshold for each level
- see `?ocat`
- for unordered categories, see `?multinom`


  
Other distributions (quickly)
===================================

- Multivariate normal (`family = "mvn"`)
  - Multivariate response, each has different smooth, allow correlation
- Cox proportional hazards (`"family = cox.ph"`)
  - Censored data: time until an event occurs, or the study was stopped
- Gaussian location-scale models (`"family = gaulss"`)
  - mean ("location") and variance ("scale") as smooths

All of these distributions have quirks! Read the manual!

`?family` and `?family.mgcv`

The end of the distribution zoo
==============
type:section 

Fancy smoothers
===============
type:section 

Cyclic smooths
==============

<p align="center">
<img alt="cyclic smooths" src="images/cyclic.png">
<br/>
<img alt="tensor of cyclic" src="images/slope-aspect.png">
</p>


***

- cyclic smooths (`bs="cc"`, `bs="cs"`)
- what if smooths need to "match up"?
- ensure up to 2nd derivs match
- need to be careful with end points
- `?smooth.construct.cc.smooth.spec`


"Simple" random effects
==============

- Earlier: "penalties can be thought of as variance components"
- We can think of random effects as splines too!
- in `mgcv` we can set `bs="re"`
- these are **simple**, non-nested random effects

```{r ext-re-get}
load("../data/drake_griffen/drake_griffen.RData")
```

```{r ext-re-model, fig.width=12, height=4}
ext_re <- gam(Nhat ~ s(day, k=50) + s(ID, bs="re"), data=pop_unhappy)
plot(ext_re, shade=TRUE, pages=1, scale=0)
```


Complicated random effects
==========================

- `gamm` --- uses spline-random effects equiv.
- cast splines as random effects, fit using `nlme`
- random effects are sparse, splines are dense
- often modelling problems with complex models
- `random=...` argument for nesting etc
- model has a `$gam` and `$lme` parts



Correlation stuctures
=====================

- again, need to use `gamm`
- `correlation=...` gives structure
- `corAR1`, `corARMA`, `corCAR1` etc
- tend to be hard to fit for SDMs


Fancy 2D smoothing
==================
type:section

Funny-shaped regions
====================

<p align="center">
<img alt="fs plot truth" src="images/soap-truth.png">
<br/>
<img alt="fs plot trprs" src="images/soap-tprs.png">
<br/>
<img alt="fs plot soap" src="images/soap-soap.png">
</p>

***

- Soap film smoother (`bs="so"`)
- Model takes boundary into account by construction
- Need to specify a boundary and internal knots
- see `?soap`


Spatial models using areas
==========================

```{r mrf}
data(columb)       ## data frame
data(columb.polys) ## district shapes list
xt <- list(polys=columb.polys) ## neighbourhood structure info for MRF
par(mfrow=c(2,2))
polys.plot(columb.polys, columb$crime, main="raw crime data")


## An important covariate added...
b <- gam(crime ~ s(district,bs="mrf",k=20,xt=xt)+s(income),
         data=columb,method="REML")

## plot fitted values by district
fv <- fitted(b)
names(fv) <- as.character(columb$district)
polys.plot(columb.polys,fv, main="fitted values")

# each "smooth"
plot(b,scheme=c(0,1))
```


***

- Markov random fields (`bs="mrf"`)
- Need to specify polygons or adjacency matrix
- Not necessarily that useful for marine work?
- see `?mrf`


Very general modelling
======================

`mgcv` can fit *anything* you can write as (on the link scale):

$$
\mathbf{y} = X\boldsymbol{\beta} \qquad \text{s.t.} \sum_j \boldsymbol{\beta}S_j \boldsymbol{\beta}
$$

if you can write your likelihood in a quadratic form, it can be part of a model in `mgcv` 

`?paraPen`


Models for large datasets
=========================

- `bam` for big additive models
- can handle simple correlation structures
- parallel (block QR decompositions)
- fast! (still experimental)
- Wood, Goude, Shaw (2015)

Fancy summary
=============

- You can do *a lot* of things in `mgcv`
- Start small, work up to complex models
- Sometimes convergence is against you
- There is *a lot* of information in the manual

<br/>
<br/>
<p align="right"><img src="images/mgcv-inside.png"></p>

Okay, that's enough
===================
type:section

<br/>
<br/>
<br/>
converged.yt/mgcv-workshop



